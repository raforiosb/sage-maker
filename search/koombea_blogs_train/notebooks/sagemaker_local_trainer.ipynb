{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "158543cb",
   "metadata": {},
   "source": [
    "# Test Trainer Sagemaker Object Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "546b5543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.local import LocalSession\n",
    "from sagemaker.estimator import Estimator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47d0350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/\" + os.path.join(*os.getcwd().split(\"/\")[:-1])\n",
    "sagemaker_session = LocalSession()\n",
    "\n",
    "sagemaker_role = \"arn:aws:iam::12345678910:role/test_role\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "096fd015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_env_variables(*env_files):\n",
    "    env_vars = dict()\n",
    "    get_values = lambda x: [(x.split(\"=\")[0], x.split(\"=\")[1])]\n",
    "    for env_file in env_files:\n",
    "        with open(env_file, \"r\") as file:\n",
    "            env_vars.update(\n",
    "                dict(\n",
    "                    [\n",
    "                        (key.strip(), value.strip()) \n",
    "                        for line in file.readlines()\n",
    "                        for key, value in get_values(line)\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "    return env_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddca091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = \"staging\"\n",
    "environment = load_env_variables(f\"../vars.{stage}.env\", \"../vars.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aaf14b",
   "metadata": {},
   "source": [
    "## Test Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e349661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "local_docker_image = \"koombea_blogs_train_koombea_blogs_train_component\"\n",
    "hyperparameters = {\n",
    "    \"min_count\":0,\n",
    "    \"size\":300,\n",
    "    \"sg\":1,\n",
    "    \"window\":15,\n",
    "    \"iter\":40,\n",
    "    \"sample\": 6e-5,\n",
    "    \"hs\": 0,\n",
    "    \"negative\": 15,\n",
    "    \"ns_exponent\": -0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83f9a685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize estimator\n",
    "estimator = Estimator(\n",
    "    image_uri = local_docker_image,\n",
    "    role = sagemaker_role,\n",
    "    instance_count = 1,\n",
    "    instance_type = \"local\",\n",
    "    hyperparameters = hyperparameters,\n",
    "    output_path = \"file://{}/{}\".format(root_dir, \"models\"),\n",
    "    sagemaker_session = sagemaker_session,\n",
    "    base_job_name = \"koombea-blogs-train-component\",\n",
    "    tags = [{\"name\": \"blogs-vector-model\"},\n",
    "            {\"staging\": stage},\n",
    "            {\"db_name\": environment.get(\"MYSQL_DBNAME\")}],\n",
    "    environment = environment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd6361d0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: koombea-blogs-train-component-2023-02-07-03-53-35-095\n",
      "INFO:sagemaker.local.local_session:Starting training job\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-gq5pe:\n",
      "    command: train\n",
      "    container_name: pj35idw5j0-algo-1-gq5pe\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: koombea_blogs_train_koombea_blogs_train_component\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-gq5pe\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmp9ydedhh_/algo-1-gq5pe/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmp9ydedhh_/algo-1-gq5pe/output:/opt/ml/output\n",
      "    - /tmp/tmp9ydedhh_/algo-1-gq5pe/input:/opt/ml/input\n",
      "    - /tmp/tmp9ydedhh_/model:/opt/ml/model\n",
      "    - /opt/ml/metadata:/opt/ml/metadata\n",
      "    - /home/ec2-user/SageMaker/search/koombea_blogs_train/data:/opt/ml/input/data/training\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmp9ydedhh_/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pj35idw5j0-algo-1-gq5pe ... \n",
      "Creating pj35idw5j0-algo-1-gq5pe ... done\n",
      "Attaching to pj35idw5j0-algo-1-gq5pe\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:37,466 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m /envs/python38/bin/python -m pip install -r requirements.txt\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: gensim<4.0,>=3.8.0 in /envs/python38/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (3.8.3)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: scikit-learn==0.24.2 in /envs/python38/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (0.24.2)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: pandas==1.2.4 in /envs/python38/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.2.4)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: python-Levenshtein==0.12.2 in /envs/python38/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (0.12.2)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: many-stop-words==0.2.2 in /envs/python38/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (0.2.2)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Collecting numpy==1.21.0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m   Using cached numpy-1.21.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: spacy==3.0 in /envs/python38/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (3.0.0)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: plotly==5.1.0 in /envs/python38/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (5.1.0)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: pydantic[dotenv]<1.8.0,>=1.7.1 in /envs/python38/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (1.7.4)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: wandb==0.11.0 in /envs/python38/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (0.11.0)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: threadpoolctl>=2.0.0 in /envs/python38/lib/python3.8/site-packages (from scikit-learn==0.24.2->-r requirements.txt (line 2)) (3.1.0)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: joblib>=0.11 in /envs/python38/lib/python3.8/site-packages (from scikit-learn==0.24.2->-r requirements.txt (line 2)) (1.2.0)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: scipy>=0.19.1 in /envs/python38/lib/python3.8/site-packages (from scikit-learn==0.24.2->-r requirements.txt (line 2)) (1.10.0)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: pytz>=2017.3 in /envs/python38/lib/python3.8/site-packages (from pandas==1.2.4->-r requirements.txt (line 3)) (2022.7.1)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: python-dateutil>=2.7.3 in /envs/python38/lib/python3.8/site-packages (from pandas==1.2.4->-r requirements.txt (line 3)) (2.8.2)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: setuptools in /envs/python38/lib/python3.8/site-packages (from python-Levenshtein==0.12.2->-r requirements.txt (line 4)) (65.6.3)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /envs/python38/lib/python3.8/site-packages (from spacy==3.0->-r requirements.txt (line 7)) (2.4.5)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /envs/python38/lib/python3.8/site-packages (from spacy==3.0->-r requirements.txt (line 7)) (0.10.1)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: pathy in /envs/python38/lib/python3.8/site-packages (from spacy==3.0->-r requirements.txt (line 7)) (0.10.1)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /envs/python38/lib/python3.8/site-packages (from spacy==3.0->-r requirements.txt (line 7)) (4.64.1)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: jinja2 in /envs/python38/lib/python3.8/site-packages (from spacy==3.0->-r requirements.txt (line 7)) (3.1.2)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /envs/python38/lib/python3.8/site-packages (from spacy==3.0->-r requirements.txt (line 7)) (3.0.8)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: typer<0.4.0,>=0.3.0 in /envs/python38/lib/python3.8/site-packages (from spacy==3.0->-r requirements.txt (line 7)) (0.3.2)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /envs/python38/lib/python3.8/site-packages (from spacy==3.0->-r requirements.txt (line 7)) (2.0.8)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: requests<3.0.0,>=2.13.0 in /envs/python38/lib/python3.8/site-packages (from spacy==3.0->-r requirements.txt (line 7)) (2.28.2)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: packaging>=20.0 in /envs/python38/lib/python3.8/site-packages (from spacy==3.0->-r requirements.txt (line 7)) (23.0)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /envs/python38/lib/python3.8/site-packages (from spacy==3.0->-r requirements.txt (line 7)) (3.0.12)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: thinc<8.1.0,>=8.0.0 in /envs/python38/lib/python3.8/site-packages (from spacy==3.0->-r requirements.txt (line 7)) (8.0.17)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /envs/python38/lib/python3.8/site-packages (from spacy==3.0->-r requirements.txt (line 7)) (1.0.9)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: blis<0.8.0,>=0.4.0 in /envs/python38/lib/python3.8/site-packages (from spacy==3.0->-r requirements.txt (line 7)) (0.7.9)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /envs/python38/lib/python3.8/site-packages (from spacy==3.0->-r requirements.txt (line 7)) (2.0.7)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: six in /envs/python38/lib/python3.8/site-packages (from plotly==5.1.0->-r requirements.txt (line 8)) (1.16.0)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: tenacity>=6.2.0 in /envs/python38/lib/python3.8/site-packages (from plotly==5.1.0->-r requirements.txt (line 8)) (8.1.0)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: urllib3>=1.26.5 in /envs/python38/lib/python3.8/site-packages (from wandb==0.11.0->-r requirements.txt (line 10)) (1.26.14)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: configparser>=3.8.1 in /envs/python38/lib/python3.8/site-packages (from wandb==0.11.0->-r requirements.txt (line 10)) (5.3.0)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: sentry-sdk>=0.4.0 in /envs/python38/lib/python3.8/site-packages (from wandb==0.11.0->-r requirements.txt (line 10)) (1.14.0)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: promise<3,>=2.0 in /envs/python38/lib/python3.8/site-packages (from wandb==0.11.0->-r requirements.txt (line 10)) (2.3)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: GitPython>=1.0.0 in /envs/python38/lib/python3.8/site-packages (from wandb==0.11.0->-r requirements.txt (line 10)) (3.1.30)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: protobuf>=3.12.0 in /envs/python38/lib/python3.8/site-packages (from wandb==0.11.0->-r requirements.txt (line 10)) (3.20.2)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: PyYAML in /envs/python38/lib/python3.8/site-packages (from wandb==0.11.0->-r requirements.txt (line 10)) (6.0)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: shortuuid>=0.5.0 in /envs/python38/lib/python3.8/site-packages (from wandb==0.11.0->-r requirements.txt (line 10)) (1.0.11)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: docker-pycreds>=0.4.0 in /envs/python38/lib/python3.8/site-packages (from wandb==0.11.0->-r requirements.txt (line 10)) (0.4.0)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: pathtools in /envs/python38/lib/python3.8/site-packages (from wandb==0.11.0->-r requirements.txt (line 10)) (0.1.2)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: Click!=8.0.0,>=7.0 in /envs/python38/lib/python3.8/site-packages (from wandb==0.11.0->-r requirements.txt (line 10)) (7.1.2)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: subprocess32>=3.5.3 in /envs/python38/lib/python3.8/site-packages (from wandb==0.11.0->-r requirements.txt (line 10)) (3.5.4)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: psutil>=5.0.0 in /envs/python38/lib/python3.8/site-packages (from wandb==0.11.0->-r requirements.txt (line 10)) (5.9.4)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: smart-open>=1.8.1 in /envs/python38/lib/python3.8/site-packages (from gensim<4.0,>=3.8.0->-r requirements.txt (line 1)) (6.3.0)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: python-dotenv>=0.10.4 in /envs/python38/lib/python3.8/site-packages (from pydantic[dotenv]<1.8.0,>=1.7.1->-r requirements.txt (line 9)) (0.21.1)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: gitdb<5,>=4.0.1 in /envs/python38/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb==0.11.0->-r requirements.txt (line 10)) (4.0.10)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: charset-normalizer<4,>=2 in /envs/python38/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.0->-r requirements.txt (line 7)) (3.0.1)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: idna<4,>=2.5 in /envs/python38/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.0->-r requirements.txt (line 7)) (3.4)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /envs/python38/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.0->-r requirements.txt (line 7)) (2022.12.7)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: MarkupSafe>=2.0 in /envs/python38/lib/python3.8/site-packages (from jinja2->spacy==3.0->-r requirements.txt (line 7)) (2.1.2)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Requirement already satisfied: smmap<6,>=3.0.1 in /envs/python38/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb==0.11.0->-r requirements.txt (line 10)) (5.0.0)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Installing collected packages: numpy\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m   Attempting uninstall: numpy\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     Found existing installation: numpy 1.23.5\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     Uninstalling numpy-1.23.5:\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m       Successfully uninstalled numpy-1.23.5\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Successfully installed numpy-1.21.0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[0m2023-02-07 03:53:44,333 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:44,336 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:44,345 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:44,353 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:44,356 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:44,367 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:44,373 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:44,375 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:44,386 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:44,390 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Training Env:\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m {\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m         \"training\": \"/opt/ml/input/data/training\"\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     },\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"current_host\": \"algo-1-gq5pe\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"current_instance_group\": \"homogeneousCluster\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"current_instance_group_hosts\": [],\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"current_instance_type\": \"local\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"distribution_hosts\": [\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m         \"algo-1-gq5pe\"\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     ],\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"distribution_instance_groups\": [],\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"framework_module\": null,\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m         \"algo-1-gq5pe\"\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     ],\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m         \"min_count\": 0,\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m         \"size\": 300,\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m         \"sg\": 1,\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m         \"window\": 15,\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m         \"iter\": 40,\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m         \"sample\": 6e-05,\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m         \"hs\": 0,\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m         \"negative\": 15,\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m         \"ns_exponent\": -0.5\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     },\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m         \"training\": {\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m         }\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     },\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"instance_groups\": [],\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"instance_groups_dict\": {},\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"is_hetero\": false,\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"is_modelparallel_enabled\": null,\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"is_smddpmprun_installed\": false,\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"job_name\": \"koombea-blogs-train-component-2023-02-07-03-53-35-095\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"master_hostname\": \"algo-1-gq5pe\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"module_dir\": \"/opt/ml/code\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"num_neurons\": 0,\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m         \"current_host\": \"algo-1-gq5pe\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m             \"algo-1-gq5pe\"\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m         ]\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     },\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m }\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Environment variables:\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_HOSTS=[\"algo-1-gq5pe\"]\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_HPS={\"hs\":0,\"iter\":40,\"min_count\":0,\"negative\":15,\"ns_exponent\":-0.5,\"sample\":6e-05,\"sg\":1,\"size\":300,\"window\":15}\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-gq5pe\",\"hosts\":[\"algo-1-gq5pe\"]}\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_CHANNELS=[\"training\"]\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_CURRENT_HOST=algo-1-gq5pe\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_CURRENT_INSTANCE_TYPE=local\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_CURRENT_INSTANCE_GROUP_HOSTS=[]\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_INSTANCE_GROUPS=[]\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_INSTANCE_GROUPS_DICT={}\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_IS_HETERO=false\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_FRAMEWORK_MODULE=\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_NUM_NEURONS=0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-gq5pe\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[],\"current_instance_type\":\"local\",\"distribution_hosts\":[\"algo-1-gq5pe\"],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1-gq5pe\"],\"hyperparameters\":{\"hs\":0,\"iter\":40,\"min_count\":0,\"negative\":15,\"ns_exponent\":-0.5,\"sample\":6e-05,\"sg\":1,\"size\":300,\"window\":15},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[],\"instance_groups_dict\":{},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"koombea-blogs-train-component-2023-02-07-03-53-35-095\",\"log_level\":20,\"master_hostname\":\"algo-1-gq5pe\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-gq5pe\",\"hosts\":[\"algo-1-gq5pe\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_USER_ARGS=[\"--hs\",\"0\",\"--iter\",\"40\",\"--min_count\",\"0\",\"--negative\",\"15\",\"--ns_exponent\",\"-0.5\",\"--sample\",\"6e-05\",\"--sg\",\"1\",\"--size\",\"300\",\"--window\",\"15\"]\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_HP_MIN_COUNT=0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_HP_SIZE=300\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_HP_SG=1\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_HP_WINDOW=15\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_HP_ITER=40\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_HP_SAMPLE=6e-05\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_HP_HS=0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_HP_NEGATIVE=15\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m SM_HP_NS_EXPONENT=-0.5\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m PYTHONPATH=/opt/ml/code:/envs/python38/bin:/envs/python38/lib/python38.zip:/envs/python38/lib/python3.8:/envs/python38/lib/python3.8/lib-dynload:/envs/python38/lib/python3.8/site-packages\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m /envs/python38/bin/python train.py --hs 0 --iter 40 --min_count 0 --negative 15 --ns_exponent -0.5 --sample 6e-05 --sg 1 --size 300 --window 15\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:44,391 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:44,391 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:49,543 - INFO - hyperparameters:\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m {\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"min_count\": \"0\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"size\": \"300\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"sg\": \"1\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"window\": \"15\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"iter\": \"40\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"sample\": \"6e-05\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"hs\": \"0\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"negative\": \"15\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"ns_exponent\": \"-0.5\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"workers\": \"2\"\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m }\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:49,543 - INFO - path_settings:\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m {\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"blogs_df_path\": \"/opt/ml/input/data/training/blogs_df_wp_koombea20stg.csv\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"en_data_path\": \"/opt/ml/input/data/training/en_data_wp_koombea20stg.json\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"es_data_path\": \"/opt/ml/input/data/training/es_data_wp_koombea20stg.json\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"model_dir\": \"/opt/ml/model\"\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m }\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:49,543 - INFO - Loading data files for training and model analysis\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkoombea-marketing\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.9 is available!  To upgrade, please run:\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.11.0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m: Resuming run \u001b[33msemantic-model-analisys-training-job-wp_koombea20stg\u001b[0m\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/koombea-marketing/koombea-website-ml\u001b[0m\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/koombea-marketing/koombea-website-ml/runs/analysis-training-job-wp_koombea20stg\u001b[0m\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /opt/ml/code/wandb/run-20230207_035350-analysis-training-job-wp_koombea20stg\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:51,346 - INFO - Training blogs model for 974 blogs of language: en using the following hyperparameters:\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m {\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"min_count\": \"0\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"size\": \"300\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"sg\": \"1\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"window\": \"15\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"iter\": \"40\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"sample\": \"6e-05\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"hs\": \"0\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"negative\": \"15\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"ns_exponent\": \"-0.5\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"workers\": \"2\"\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m }\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:51,349 - INFO - collecting all words and their counts\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:51,349 - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:51,468 - INFO - collected 12115 word types from a corpus of 503174 raw words and 974 sentences\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:51,469 - INFO - Loading a fresh vocabulary\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:51,675 - INFO - effective_min_count=0 retains 12115 unique words (100% of original 12115, drops 0)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:51,675 - INFO - effective_min_count=0 leaves 503174 word corpus (100% of original 503174, drops 0)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:51,713 - INFO - deleting the raw counts dictionary of 12115 items\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:51,714 - INFO - sample=6e-05 downsamples 1080 most-common words\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:51,714 - INFO - downsampling leaves estimated 225766 word corpus (44.9% of prior 503174)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:51,750 - INFO - estimated required memory for 12115 words and 300 dimensions: 35133500 bytes\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:51,750 - INFO - resetting layer weights\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:54,906 - INFO - training model with 2 workers on 12115 vocabulary and 300 features, using sg=1 hs=0 sample=6e-05 negative=15 window=15\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:56,141 - INFO - EPOCH 1 - PROGRESS: at 4.21% examples, 8069 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:57,303 - INFO - EPOCH 1 - PROGRESS: at 11.29% examples, 10078 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:58,341 - INFO - EPOCH 1 - PROGRESS: at 16.84% examples, 11171 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:53:59,384 - INFO - EPOCH 1 - PROGRESS: at 28.95% examples, 13715 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:00,438 - INFO - EPOCH 1 - PROGRESS: at 35.42% examples, 13686 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:01,731 - INFO - EPOCH 1 - PROGRESS: at 44.46% examples, 13808 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:03,032 - INFO - EPOCH 1 - PROGRESS: at 49.79% examples, 13080 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:04,324 - INFO - EPOCH 1 - PROGRESS: at 57.70% examples, 13570 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:05,548 - INFO - EPOCH 1 - PROGRESS: at 67.25% examples, 14334 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:06,662 - INFO - EPOCH 1 - PROGRESS: at 78.75% examples, 15069 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:07,822 - INFO - EPOCH 1 - PROGRESS: at 89.32% examples, 15592 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:08,600 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:08,946 - INFO - EPOCH 1 - PROGRESS: at 100.00% examples, 16094 words/s, in_qsize 0, out_qsize 1\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:08,947 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:08,947 - INFO - EPOCH - 1 : training on 503174 raw words (225735 effective words) took 14.0s, 16093 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:09,997 - INFO - EPOCH 2 - PROGRESS: at 7.08% examples, 13894 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:11,007 - INFO - EPOCH 2 - PROGRESS: at 16.94% examples, 18465 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:12,281 - INFO - EPOCH 2 - PROGRESS: at 28.95% examples, 18356 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:13,522 - INFO - EPOCH 2 - PROGRESS: at 40.04% examples, 18564 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:14,723 - INFO - EPOCH 2 - PROGRESS: at 51.33% examples, 19170 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:15,942 - INFO - EPOCH 2 - PROGRESS: at 60.47% examples, 19400 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:17,113 - INFO - EPOCH 2 - PROGRESS: at 70.94% examples, 19694 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:18,295 - INFO - EPOCH 2 - PROGRESS: at 82.34% examples, 19831 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:19,314 - INFO - EPOCH 2 - PROGRESS: at 92.81% examples, 20195 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:19,746 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:20,051 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:20,051 - INFO - EPOCH - 2 : training on 503174 raw words (225927 effective words) took 11.1s, 20347 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:21,089 - INFO - EPOCH 3 - PROGRESS: at 9.14% examples, 18875 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:22,498 - INFO - EPOCH 3 - PROGRESS: at 19.20% examples, 17616 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:23,549 - INFO - EPOCH 3 - PROGRESS: at 31.01% examples, 18840 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:24,773 - INFO - EPOCH 3 - PROGRESS: at 42.30% examples, 18919 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:26,021 - INFO - EPOCH 3 - PROGRESS: at 53.08% examples, 19232 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:27,178 - INFO - EPOCH 3 - PROGRESS: at 62.01% examples, 19624 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:28,221 - INFO - EPOCH 3 - PROGRESS: at 72.79% examples, 20160 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:29,299 - INFO - EPOCH 3 - PROGRESS: at 82.44% examples, 20003 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:30,464 - INFO - EPOCH 3 - PROGRESS: at 92.81% examples, 20063 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:30,947 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:31,184 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:31,184 - INFO - EPOCH - 3 : training on 503174 raw words (225784 effective words) took 11.1s, 20283 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:32,205 - INFO - EPOCH 4 - PROGRESS: at 7.08% examples, 14360 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:33,599 - INFO - EPOCH 4 - PROGRESS: at 18.69% examples, 17698 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:34,679 - INFO - EPOCH 4 - PROGRESS: at 31.01% examples, 18804 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:35,975 - INFO - EPOCH 4 - PROGRESS: at 42.30% examples, 18608 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:37,323 - INFO - EPOCH 4 - PROGRESS: at 52.98% examples, 18665 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:38,498 - INFO - EPOCH 4 - PROGRESS: at 62.01% examples, 19129 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:39,503 - INFO - EPOCH 4 - PROGRESS: at 70.94% examples, 19294 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:40,884 - INFO - EPOCH 4 - PROGRESS: at 82.44% examples, 19063 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:41,943 - INFO - EPOCH 4 - PROGRESS: at 89.32% examples, 18690 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:43,255 - INFO - EPOCH 4 - PROGRESS: at 98.25% examples, 18312 words/s, in_qsize 2, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:43,271 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:43,278 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:43,278 - INFO - EPOCH - 4 : training on 503174 raw words (225584 effective words) took 12.1s, 18653 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:44,650 - INFO - EPOCH 5 - PROGRESS: at 9.14% examples, 14293 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:45,915 - INFO - EPOCH 5 - PROGRESS: at 18.69% examples, 16304 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:47,003 - INFO - EPOCH 5 - PROGRESS: at 31.01% examples, 17759 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:48,336 - INFO - EPOCH 5 - PROGRESS: at 42.30% examples, 17704 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:49,798 - INFO - EPOCH 5 - PROGRESS: at 49.79% examples, 16295 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:50,943 - INFO - EPOCH 5 - PROGRESS: at 54.72% examples, 15534 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:52,078 - INFO - EPOCH 5 - PROGRESS: at 59.03% examples, 14998 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:53,336 - INFO - EPOCH 5 - PROGRESS: at 63.76% examples, 14312 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:54,889 - INFO - EPOCH 5 - PROGRESS: at 70.94% examples, 13821 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:56,219 - INFO - EPOCH 5 - PROGRESS: at 78.44% examples, 13679 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:57,370 - INFO - EPOCH 5 - PROGRESS: at 89.32% examples, 14293 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:58,198 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:58,603 - INFO - EPOCH 5 - PROGRESS: at 100.00% examples, 14742 words/s, in_qsize 0, out_qsize 1\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:58,605 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:58,605 - INFO - EPOCH - 5 : training on 503174 raw words (225891 effective words) took 15.3s, 14740 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:54:59,770 - INFO - EPOCH 6 - PROGRESS: at 9.14% examples, 16639 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:00,771 - INFO - EPOCH 6 - PROGRESS: at 14.99% examples, 15262 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:02,689 - INFO - EPOCH 6 - PROGRESS: at 20.94% examples, 11665 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:03,725 - INFO - EPOCH 6 - PROGRESS: at 26.80% examples, 10982 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:05,094 - INFO - EPOCH 6 - PROGRESS: at 33.26% examples, 10868 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:06,278 - INFO - EPOCH 6 - PROGRESS: at 41.89% examples, 11574 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:07,534 - INFO - EPOCH 6 - PROGRESS: at 51.54% examples, 12335 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:08,680 - INFO - EPOCH 6 - PROGRESS: at 59.03% examples, 13062 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:09,829 - INFO - EPOCH 6 - PROGRESS: at 67.25% examples, 13555 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:11,199 - INFO - EPOCH 6 - PROGRESS: at 78.75% examples, 14045 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:12,437 - INFO - EPOCH 6 - PROGRESS: at 89.32% examples, 14535 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:13,285 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:13,556 - INFO - EPOCH 6 - PROGRESS: at 100.00% examples, 15088 words/s, in_qsize 0, out_qsize 1\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:13,557 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:13,557 - INFO - EPOCH - 6 : training on 503174 raw words (225565 effective words) took 15.0s, 15087 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:14,632 - INFO - EPOCH 7 - PROGRESS: at 7.08% examples, 13467 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:15,674 - INFO - EPOCH 7 - PROGRESS: at 14.99% examples, 15584 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:16,842 - INFO - EPOCH 7 - PROGRESS: at 26.80% examples, 17166 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:18,244 - INFO - EPOCH 7 - PROGRESS: at 37.78% examples, 17057 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:19,294 - INFO - EPOCH 7 - PROGRESS: at 48.56% examples, 17797 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:20,591 - INFO - EPOCH 7 - PROGRESS: at 56.26% examples, 17545 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:21,673 - INFO - EPOCH 7 - PROGRESS: at 65.30% examples, 18228 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:22,916 - INFO - EPOCH 7 - PROGRESS: at 74.74% examples, 18016 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:23,928 - INFO - EPOCH 7 - PROGRESS: at 84.29% examples, 18260 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:24,983 - INFO - EPOCH 7 - PROGRESS: at 94.66% examples, 18636 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:25,438 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:25,722 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:25,723 - INFO - EPOCH - 7 : training on 503174 raw words (225721 effective words) took 12.2s, 18555 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:26,771 - INFO - EPOCH 8 - PROGRESS: at 7.08% examples, 13913 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:27,998 - INFO - EPOCH 8 - PROGRESS: at 16.94% examples, 16701 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:29,123 - INFO - EPOCH 8 - PROGRESS: at 28.95% examples, 17987 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:30,260 - INFO - EPOCH 8 - PROGRESS: at 37.68% examples, 17736 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:31,293 - INFO - EPOCH 8 - PROGRESS: at 46.41% examples, 17555 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:32,566 - INFO - EPOCH 8 - PROGRESS: at 56.26% examples, 18084 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:33,609 - INFO - EPOCH 8 - PROGRESS: at 62.01% examples, 17794 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:34,814 - INFO - EPOCH 8 - PROGRESS: at 70.94% examples, 17691 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:35,973 - INFO - EPOCH 8 - PROGRESS: at 82.34% examples, 18098 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:37,138 - INFO - EPOCH 8 - PROGRESS: at 92.81% examples, 18337 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:37,685 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:37,995 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:37,996 - INFO - EPOCH - 8 : training on 503174 raw words (226043 effective words) took 12.3s, 18419 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:39,213 - INFO - EPOCH 9 - PROGRESS: at 9.14% examples, 15983 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:40,266 - INFO - EPOCH 9 - PROGRESS: at 16.94% examples, 16745 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:41,317 - INFO - EPOCH 9 - PROGRESS: at 26.80% examples, 16949 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:42,355 - INFO - EPOCH 9 - PROGRESS: at 35.42% examples, 17337 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:43,774 - INFO - EPOCH 9 - PROGRESS: at 46.41% examples, 16886 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:45,064 - INFO - EPOCH 9 - PROGRESS: at 56.16% examples, 17385 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:46,291 - INFO - EPOCH 9 - PROGRESS: at 65.30% examples, 17816 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:47,471 - INFO - EPOCH 9 - PROGRESS: at 74.74% examples, 17809 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:48,609 - INFO - EPOCH 9 - PROGRESS: at 86.14% examples, 18219 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:49,781 - INFO - EPOCH 9 - PROGRESS: at 96.51% examples, 18419 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:49,935 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:50,141 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:50,141 - INFO - EPOCH - 9 : training on 503174 raw words (225590 effective words) took 12.1s, 18577 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:51,147 - INFO - EPOCH 10 - PROGRESS: at 7.08% examples, 14465 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:52,168 - INFO - EPOCH 10 - PROGRESS: at 14.99% examples, 16292 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:53,192 - INFO - EPOCH 10 - PROGRESS: at 26.80% examples, 18463 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:54,262 - INFO - EPOCH 10 - PROGRESS: at 35.42% examples, 18357 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:55,267 - INFO - EPOCH 10 - PROGRESS: at 44.15% examples, 18261 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:56,345 - INFO - EPOCH 10 - PROGRESS: at 51.33% examples, 17839 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:57,486 - INFO - EPOCH 10 - PROGRESS: at 60.57% examples, 18555 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:58,665 - INFO - EPOCH 10 - PROGRESS: at 70.94% examples, 18857 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:55:59,816 - INFO - EPOCH 10 - PROGRESS: at 82.34% examples, 19145 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:00,913 - INFO - EPOCH 10 - PROGRESS: at 91.07% examples, 19059 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:02,205 - INFO - EPOCH 10 - PROGRESS: at 98.15% examples, 18366 words/s, in_qsize 2, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:02,273 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:02,633 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:02,634 - INFO - EPOCH - 10 : training on 503174 raw words (225831 effective words) took 12.5s, 18079 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:04,073 - INFO - EPOCH 11 - PROGRESS: at 7.08% examples, 10185 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:05,109 - INFO - EPOCH 11 - PROGRESS: at 14.99% examples, 13377 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:06,213 - INFO - EPOCH 11 - PROGRESS: at 26.80% examples, 15776 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:07,517 - INFO - EPOCH 11 - PROGRESS: at 37.68% examples, 16511 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:08,524 - INFO - EPOCH 11 - PROGRESS: at 48.56% examples, 17413 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:09,701 - INFO - EPOCH 11 - PROGRESS: at 56.26% examples, 17512 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:10,879 - INFO - EPOCH 11 - PROGRESS: at 65.30% examples, 18000 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:11,955 - INFO - EPOCH 11 - PROGRESS: at 76.69% examples, 18592 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:13,102 - INFO - EPOCH 11 - PROGRESS: at 86.14% examples, 18515 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:14,184 - INFO - EPOCH 11 - PROGRESS: at 96.51% examples, 18819 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:14,268 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:14,557 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:14,557 - INFO - EPOCH - 11 : training on 503174 raw words (225904 effective words) took 11.9s, 18957 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:15,686 - INFO - EPOCH 12 - PROGRESS: at 7.08% examples, 13015 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:17,108 - INFO - EPOCH 12 - PROGRESS: at 16.94% examples, 14907 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:18,323 - INFO - EPOCH 12 - PROGRESS: at 28.95% examples, 16209 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:19,715 - INFO - EPOCH 12 - PROGRESS: at 40.04% examples, 16424 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:20,967 - INFO - EPOCH 12 - PROGRESS: at 51.33% examples, 17240 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:21,988 - INFO - EPOCH 12 - PROGRESS: at 59.03% examples, 17731 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:23,007 - INFO - EPOCH 12 - PROGRESS: at 67.25% examples, 18016 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:24,055 - INFO - EPOCH 12 - PROGRESS: at 76.69% examples, 18198 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:25,239 - INFO - EPOCH 12 - PROGRESS: at 86.04% examples, 18066 words/s, in_qsize 3, out_qsize 1\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:26,359 - INFO - EPOCH 12 - PROGRESS: at 96.51% examples, 18377 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:26,541 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:26,762 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:26,763 - INFO - EPOCH - 12 : training on 503174 raw words (225561 effective words) took 12.2s, 18482 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:27,957 - INFO - EPOCH 13 - PROGRESS: at 7.08% examples, 12232 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:29,015 - INFO - EPOCH 13 - PROGRESS: at 15.09% examples, 14808 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:30,300 - INFO - EPOCH 13 - PROGRESS: at 26.80% examples, 15955 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:31,338 - INFO - EPOCH 13 - PROGRESS: at 35.42% examples, 16537 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:32,477 - INFO - EPOCH 13 - PROGRESS: at 46.30% examples, 17184 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:33,620 - INFO - EPOCH 13 - PROGRESS: at 54.62% examples, 17426 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:34,631 - INFO - EPOCH 13 - PROGRESS: at 62.01% examples, 17823 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:35,854 - INFO - EPOCH 13 - PROGRESS: at 70.94% examples, 17669 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:36,868 - INFO - EPOCH 13 - PROGRESS: at 80.49% examples, 17904 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:37,870 - INFO - EPOCH 13 - PROGRESS: at 87.58% examples, 17773 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:39,154 - INFO - EPOCH 13 - PROGRESS: at 98.15% examples, 17891 words/s, in_qsize 2, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:39,165 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:39,524 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:39,524 - INFO - EPOCH - 13 : training on 503174 raw words (225886 effective words) took 12.8s, 17702 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:40,767 - INFO - EPOCH 14 - PROGRESS: at 7.08% examples, 11780 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:41,882 - INFO - EPOCH 14 - PROGRESS: at 14.99% examples, 14022 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:43,130 - INFO - EPOCH 14 - PROGRESS: at 26.80% examples, 15600 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:44,199 - INFO - EPOCH 14 - PROGRESS: at 35.42% examples, 16146 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:45,272 - INFO - EPOCH 14 - PROGRESS: at 44.15% examples, 16229 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:46,566 - INFO - EPOCH 14 - PROGRESS: at 54.72% examples, 16888 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:47,678 - INFO - EPOCH 14 - PROGRESS: at 62.01% examples, 17168 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:48,843 - INFO - EPOCH 14 - PROGRESS: at 72.79% examples, 17672 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:49,846 - INFO - EPOCH 14 - PROGRESS: at 82.34% examples, 17933 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:51,212 - INFO - EPOCH 14 - PROGRESS: at 92.92% examples, 17883 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:51,788 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:52,140 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:52,141 - INFO - EPOCH - 14 : training on 503174 raw words (225719 effective words) took 12.6s, 17892 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:53,172 - INFO - EPOCH 15 - PROGRESS: at 7.08% examples, 14223 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:54,453 - INFO - EPOCH 15 - PROGRESS: at 16.94% examples, 16482 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:55,503 - INFO - EPOCH 15 - PROGRESS: at 26.80% examples, 16771 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:56,893 - INFO - EPOCH 15 - PROGRESS: at 37.68% examples, 16930 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:58,029 - INFO - EPOCH 15 - PROGRESS: at 48.56% examples, 17368 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:56:59,263 - INFO - EPOCH 15 - PROGRESS: at 56.26% examples, 17345 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:00,387 - INFO - EPOCH 15 - PROGRESS: at 63.55% examples, 17502 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:02,013 - INFO - EPOCH 15 - PROGRESS: at 72.79% examples, 16693 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:03,040 - INFO - EPOCH 15 - PROGRESS: at 76.69% examples, 15877 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:04,457 - INFO - EPOCH 15 - PROGRESS: at 82.44% examples, 15038 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:05,892 - INFO - EPOCH 15 - PROGRESS: at 89.63% examples, 14654 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:06,948 - INFO - EPOCH 15 - PROGRESS: at 96.51% examples, 14677 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:07,460 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:07,513 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:07,513 - INFO - EPOCH - 15 : training on 503174 raw words (226050 effective words) took 15.4s, 14706 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:08,984 - INFO - EPOCH 16 - PROGRESS: at 7.08% examples, 9963 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:10,162 - INFO - EPOCH 16 - PROGRESS: at 15.09% examples, 12570 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:11,509 - INFO - EPOCH 16 - PROGRESS: at 24.13% examples, 13026 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:12,989 - INFO - EPOCH 16 - PROGRESS: at 33.26% examples, 12904 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:14,234 - INFO - EPOCH 16 - PROGRESS: at 42.30% examples, 13305 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:15,599 - INFO - EPOCH 16 - PROGRESS: at 51.33% examples, 13688 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:16,613 - INFO - EPOCH 16 - PROGRESS: at 59.03% examples, 14478 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:17,644 - INFO - EPOCH 16 - PROGRESS: at 67.25% examples, 15050 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:18,708 - INFO - EPOCH 16 - PROGRESS: at 76.69% examples, 15460 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:19,737 - INFO - EPOCH 16 - PROGRESS: at 86.14% examples, 15832 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:20,833 - INFO - EPOCH 16 - PROGRESS: at 96.51% examples, 16303 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:21,096 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:21,208 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:21,209 - INFO - EPOCH - 16 : training on 503174 raw words (225914 effective words) took 13.7s, 16497 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:22,436 - INFO - EPOCH 17 - PROGRESS: at 9.14% examples, 15843 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:23,556 - INFO - EPOCH 17 - PROGRESS: at 18.69% examples, 18194 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:24,878 - INFO - EPOCH 17 - PROGRESS: at 28.95% examples, 16615 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:26,106 - INFO - EPOCH 17 - PROGRESS: at 40.04% examples, 17234 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:27,312 - INFO - EPOCH 17 - PROGRESS: at 51.33% examples, 18053 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:28,411 - INFO - EPOCH 17 - PROGRESS: at 59.03% examples, 18250 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:29,442 - INFO - EPOCH 17 - PROGRESS: at 65.30% examples, 17937 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:30,496 - INFO - EPOCH 17 - PROGRESS: at 74.74% examples, 18141 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:31,532 - INFO - EPOCH 17 - PROGRESS: at 80.29% examples, 17490 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:32,663 - INFO - EPOCH 17 - PROGRESS: at 91.07% examples, 17857 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:33,374 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:33,474 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:33,475 - INFO - EPOCH - 17 : training on 503174 raw words (224996 effective words) took 12.3s, 18344 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:34,485 - INFO - EPOCH 18 - PROGRESS: at 9.14% examples, 19244 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:35,496 - INFO - EPOCH 18 - PROGRESS: at 14.99% examples, 16358 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:36,810 - INFO - EPOCH 18 - PROGRESS: at 26.80% examples, 16879 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:37,836 - INFO - EPOCH 18 - PROGRESS: at 35.42% examples, 17317 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:39,030 - INFO - EPOCH 18 - PROGRESS: at 46.41% examples, 17572 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:40,308 - INFO - EPOCH 18 - PROGRESS: at 56.16% examples, 18017 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:41,628 - INFO - EPOCH 18 - PROGRESS: at 65.50% examples, 18209 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:42,875 - INFO - EPOCH 18 - PROGRESS: at 76.69% examples, 18395 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:43,964 - INFO - EPOCH 18 - PROGRESS: at 87.89% examples, 18814 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:45,290 - INFO - EPOCH 18 - PROGRESS: at 98.15% examples, 18752 words/s, in_qsize 2, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:45,308 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:45,352 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:45,352 - INFO - EPOCH - 18 : training on 503174 raw words (225930 effective words) took 11.9s, 19024 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:46,531 - INFO - EPOCH 19 - PROGRESS: at 7.08% examples, 12420 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:47,577 - INFO - EPOCH 19 - PROGRESS: at 16.94% examples, 17085 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:48,635 - INFO - EPOCH 19 - PROGRESS: at 26.80% examples, 17171 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:50,297 - INFO - EPOCH 19 - PROGRESS: at 33.16% examples, 14334 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:51,314 - INFO - EPOCH 19 - PROGRESS: at 37.68% examples, 13525 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:52,347 - INFO - EPOCH 19 - PROGRESS: at 42.30% examples, 12801 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:53,754 - INFO - EPOCH 19 - PROGRESS: at 48.56% examples, 12195 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:54,873 - INFO - EPOCH 19 - PROGRESS: at 53.08% examples, 12094 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:56,009 - INFO - EPOCH 19 - PROGRESS: at 57.70% examples, 11985 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:57,148 - INFO - EPOCH 19 - PROGRESS: at 65.30% examples, 12562 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:58,276 - INFO - EPOCH 19 - PROGRESS: at 74.74% examples, 13091 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:57:59,461 - INFO - EPOCH 19 - PROGRESS: at 86.04% examples, 13712 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:00,536 - INFO - EPOCH 19 - PROGRESS: at 94.66% examples, 14043 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:01,170 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:01,178 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:01,178 - INFO - EPOCH - 19 : training on 503174 raw words (226134 effective words) took 15.8s, 14291 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:02,590 - INFO - EPOCH 20 - PROGRESS: at 5.03% examples, 6945 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:03,949 - INFO - EPOCH 20 - PROGRESS: at 11.29% examples, 8674 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:04,966 - INFO - EPOCH 20 - PROGRESS: at 16.84% examples, 10074 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:06,097 - INFO - EPOCH 20 - PROGRESS: at 28.95% examples, 12435 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:07,481 - INFO - EPOCH 20 - PROGRESS: at 40.04% examples, 13443 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:08,507 - INFO - EPOCH 20 - PROGRESS: at 49.79% examples, 14456 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:09,712 - INFO - EPOCH 20 - PROGRESS: at 57.60% examples, 14973 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:10,905 - INFO - EPOCH 20 - PROGRESS: at 67.25% examples, 15650 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:12,120 - INFO - EPOCH 20 - PROGRESS: at 78.44% examples, 16180 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:13,339 - INFO - EPOCH 20 - PROGRESS: at 89.63% examples, 16557 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:14,305 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:14,570 - INFO - EPOCH 20 - PROGRESS: at 100.00% examples, 16868 words/s, in_qsize 0, out_qsize 1\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:14,571 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:14,572 - INFO - EPOCH - 20 : training on 503174 raw words (225852 effective words) took 13.4s, 16865 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:15,597 - INFO - EPOCH 21 - PROGRESS: at 9.14% examples, 18991 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:16,604 - INFO - EPOCH 21 - PROGRESS: at 16.94% examples, 18724 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:18,014 - INFO - EPOCH 21 - PROGRESS: at 28.95% examples, 17752 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:19,162 - INFO - EPOCH 21 - PROGRESS: at 40.04% examples, 18475 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:20,211 - INFO - EPOCH 21 - PROGRESS: at 49.79% examples, 18793 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:21,502 - INFO - EPOCH 21 - PROGRESS: at 59.03% examples, 18988 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:22,544 - INFO - EPOCH 21 - PROGRESS: at 69.10% examples, 19583 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:23,561 - INFO - EPOCH 21 - PROGRESS: at 78.75% examples, 19675 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:24,820 - INFO - EPOCH 21 - PROGRESS: at 89.32% examples, 19628 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:25,637 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:25,979 - INFO - EPOCH 21 - PROGRESS: at 100.00% examples, 19802 words/s, in_qsize 0, out_qsize 1\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:25,980 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:25,981 - INFO - EPOCH - 21 : training on 503174 raw words (225862 effective words) took 11.4s, 19799 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:26,988 - INFO - EPOCH 22 - PROGRESS: at 9.14% examples, 19204 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:28,392 - INFO - EPOCH 22 - PROGRESS: at 19.20% examples, 17786 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:29,862 - INFO - EPOCH 22 - PROGRESS: at 33.26% examples, 18205 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:30,988 - INFO - EPOCH 22 - PROGRESS: at 44.15% examples, 18653 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:32,029 - INFO - EPOCH 22 - PROGRESS: at 53.08% examples, 18978 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:33,158 - INFO - EPOCH 22 - PROGRESS: at 62.01% examples, 19504 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:34,230 - INFO - EPOCH 22 - PROGRESS: at 70.94% examples, 19426 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:35,313 - INFO - EPOCH 22 - PROGRESS: at 80.49% examples, 19384 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:36,481 - INFO - EPOCH 22 - PROGRESS: at 91.07% examples, 19534 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:37,211 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:37,445 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:37,447 - INFO - EPOCH - 22 : training on 503174 raw words (225431 effective words) took 11.5s, 19664 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:38,497 - INFO - EPOCH 23 - PROGRESS: at 7.08% examples, 13842 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:39,945 - INFO - EPOCH 23 - PROGRESS: at 19.20% examples, 17131 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:41,052 - INFO - EPOCH 23 - PROGRESS: at 31.01% examples, 18254 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:42,308 - INFO - EPOCH 23 - PROGRESS: at 42.30% examples, 18394 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:43,627 - INFO - EPOCH 23 - PROGRESS: at 53.08% examples, 18640 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:44,793 - INFO - EPOCH 23 - PROGRESS: at 62.01% examples, 19115 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:46,034 - INFO - EPOCH 23 - PROGRESS: at 72.79% examples, 19231 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:47,101 - INFO - EPOCH 23 - PROGRESS: at 84.29% examples, 19673 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:48,248 - INFO - EPOCH 23 - PROGRESS: at 94.66% examples, 19764 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:48,672 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:48,789 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:48,789 - INFO - EPOCH - 23 : training on 503174 raw words (226304 effective words) took 11.3s, 19955 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:50,186 - INFO - EPOCH 24 - PROGRESS: at 10.99% examples, 17144 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:51,260 - INFO - EPOCH 24 - PROGRESS: at 20.94% examples, 19365 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:52,541 - INFO - EPOCH 24 - PROGRESS: at 33.16% examples, 18874 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:53,787 - INFO - EPOCH 24 - PROGRESS: at 46.30% examples, 19666 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:54,970 - INFO - EPOCH 24 - PROGRESS: at 56.16% examples, 19953 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:56,009 - INFO - EPOCH 24 - PROGRESS: at 63.55% examples, 20000 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:57,247 - INFO - EPOCH 24 - PROGRESS: at 74.74% examples, 19964 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:58,315 - INFO - EPOCH 24 - PROGRESS: at 86.04% examples, 20283 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:59,363 - INFO - EPOCH 24 - PROGRESS: at 96.51% examples, 20523 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:59,410 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:59,746 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:58:59,747 - INFO - EPOCH - 24 : training on 503174 raw words (225642 effective words) took 11.0s, 20594 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:00,862 - INFO - EPOCH 25 - PROGRESS: at 7.08% examples, 13125 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:02,177 - INFO - EPOCH 25 - PROGRESS: at 14.99% examples, 13656 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:03,356 - INFO - EPOCH 25 - PROGRESS: at 21.36% examples, 13025 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:04,465 - INFO - EPOCH 25 - PROGRESS: at 31.01% examples, 13959 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:05,834 - INFO - EPOCH 25 - PROGRESS: at 41.89% examples, 14611 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:07,244 - INFO - EPOCH 25 - PROGRESS: at 53.08% examples, 15342 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:08,320 - INFO - EPOCH 25 - PROGRESS: at 60.57% examples, 15894 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:09,346 - INFO - EPOCH 25 - PROGRESS: at 70.94% examples, 16738 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:10,453 - INFO - EPOCH 25 - PROGRESS: at 82.34% examples, 17307 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:11,562 - INFO - EPOCH 25 - PROGRESS: at 92.81% examples, 17690 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:12,058 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:12,297 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:12,297 - INFO - EPOCH - 25 : training on 503174 raw words (225757 effective words) took 12.5s, 17991 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:13,341 - INFO - EPOCH 26 - PROGRESS: at 9.14% examples, 18612 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:14,456 - INFO - EPOCH 26 - PROGRESS: at 16.94% examples, 17641 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:15,467 - INFO - EPOCH 26 - PROGRESS: at 28.95% examples, 19357 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:16,819 - INFO - EPOCH 26 - PROGRESS: at 39.94% examples, 18833 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:17,844 - INFO - EPOCH 26 - PROGRESS: at 49.79% examples, 19155 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:19,107 - INFO - EPOCH 26 - PROGRESS: at 57.70% examples, 18749 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:20,328 - INFO - EPOCH 26 - PROGRESS: at 67.25% examples, 18984 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:21,476 - INFO - EPOCH 26 - PROGRESS: at 78.75% examples, 19309 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:22,641 - INFO - EPOCH 26 - PROGRESS: at 89.32% examples, 19475 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:23,621 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:23,891 - INFO - EPOCH 26 - PROGRESS: at 100.00% examples, 19488 words/s, in_qsize 0, out_qsize 1\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:23,892 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:23,893 - INFO - EPOCH - 26 : training on 503174 raw words (225920 effective words) took 11.6s, 19485 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:25,166 - INFO - EPOCH 27 - PROGRESS: at 9.14% examples, 15293 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:26,550 - INFO - EPOCH 27 - PROGRESS: at 19.20% examples, 16084 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:27,862 - INFO - EPOCH 27 - PROGRESS: at 33.16% examples, 17827 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:28,919 - INFO - EPOCH 27 - PROGRESS: at 41.89% examples, 17721 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:30,076 - INFO - EPOCH 27 - PROGRESS: at 53.08% examples, 18606 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:31,272 - INFO - EPOCH 27 - PROGRESS: at 62.01% examples, 18992 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:32,448 - INFO - EPOCH 27 - PROGRESS: at 72.79% examples, 19271 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:33,562 - INFO - EPOCH 27 - PROGRESS: at 82.34% examples, 19160 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:34,599 - INFO - EPOCH 27 - PROGRESS: at 92.81% examples, 19540 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:35,277 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:35,423 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:35,423 - INFO - EPOCH - 27 : training on 503174 raw words (225877 effective words) took 11.5s, 19592 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:36,627 - INFO - EPOCH 28 - PROGRESS: at 7.08% examples, 12157 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:37,710 - INFO - EPOCH 28 - PROGRESS: at 16.94% examples, 16647 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:38,851 - INFO - EPOCH 28 - PROGRESS: at 28.95% examples, 17849 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:39,948 - INFO - EPOCH 28 - PROGRESS: at 37.68% examples, 17789 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:41,128 - INFO - EPOCH 28 - PROGRESS: at 48.56% examples, 17923 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:42,284 - INFO - EPOCH 28 - PROGRESS: at 57.70% examples, 18586 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:43,535 - INFO - EPOCH 28 - PROGRESS: at 67.15% examples, 18742 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:44,750 - INFO - EPOCH 28 - PROGRESS: at 78.75% examples, 18967 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:45,960 - INFO - EPOCH 28 - PROGRESS: at 87.89% examples, 18717 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:47,049 - INFO - EPOCH 28 - PROGRESS: at 98.15% examples, 19050 words/s, in_qsize 2, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:47,071 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:47,118 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:47,119 - INFO - EPOCH - 28 : training on 503174 raw words (225629 effective words) took 11.7s, 19302 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:48,176 - INFO - EPOCH 29 - PROGRESS: at 7.08% examples, 13997 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:49,538 - INFO - EPOCH 29 - PROGRESS: at 18.69% examples, 17742 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:50,667 - INFO - EPOCH 29 - PROGRESS: at 31.01% examples, 18632 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:52,002 - INFO - EPOCH 29 - PROGRESS: at 42.30% examples, 18346 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:53,130 - INFO - EPOCH 29 - PROGRESS: at 51.54% examples, 18383 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:54,247 - INFO - EPOCH 29 - PROGRESS: at 60.57% examples, 19126 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:55,298 - INFO - EPOCH 29 - PROGRESS: at 67.25% examples, 18619 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:56,393 - INFO - EPOCH 29 - PROGRESS: at 78.75% examples, 19099 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:57,473 - INFO - EPOCH 29 - PROGRESS: at 87.89% examples, 19077 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:58,528 - INFO - EPOCH 29 - PROGRESS: at 96.51% examples, 19052 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:58,614 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:58,920 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 03:59:58,921 - INFO - EPOCH - 29 : training on 503174 raw words (226102 effective words) took 11.8s, 19161 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:00,351 - INFO - EPOCH 30 - PROGRESS: at 7.08% examples, 10395 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:02,234 - INFO - EPOCH 30 - PROGRESS: at 11.29% examples, 7316 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:04,354 - INFO - EPOCH 30 - PROGRESS: at 14.99% examples, 6129 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:05,723 - INFO - EPOCH 30 - PROGRESS: at 18.69% examples, 6315 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:06,886 - INFO - EPOCH 30 - PROGRESS: at 24.54% examples, 6489 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:08,148 - INFO - EPOCH 30 - PROGRESS: at 31.11% examples, 7165 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:09,189 - INFO - EPOCH 30 - PROGRESS: at 35.63% examples, 7378 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:10,314 - INFO - EPOCH 30 - PROGRESS: at 42.30% examples, 7852 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:11,469 - INFO - EPOCH 30 - PROGRESS: at 49.18% examples, 8461 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:12,669 - INFO - EPOCH 30 - PROGRESS: at 56.26% examples, 9000 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:13,989 - INFO - EPOCH 30 - PROGRESS: at 63.76% examples, 9546 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:15,038 - INFO - EPOCH 30 - PROGRESS: at 70.94% examples, 9991 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:16,414 - INFO - EPOCH 30 - PROGRESS: at 80.60% examples, 10390 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:17,448 - INFO - EPOCH 30 - PROGRESS: at 87.89% examples, 10659 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:18,534 - INFO - EPOCH 30 - PROGRESS: at 98.15% examples, 11308 words/s, in_qsize 2, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:18,550 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:18,659 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:18,660 - INFO - EPOCH - 30 : training on 503174 raw words (225856 effective words) took 19.7s, 11454 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:19,705 - INFO - EPOCH 31 - PROGRESS: at 9.14% examples, 18557 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:20,914 - INFO - EPOCH 31 - PROGRESS: at 18.69% examples, 18912 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:22,283 - INFO - EPOCH 31 - PROGRESS: at 31.01% examples, 18151 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:23,387 - INFO - EPOCH 31 - PROGRESS: at 44.15% examples, 19725 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:24,560 - INFO - EPOCH 31 - PROGRESS: at 54.72% examples, 20111 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:25,562 - INFO - EPOCH 31 - PROGRESS: at 62.01% examples, 20244 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:26,835 - INFO - EPOCH 31 - PROGRESS: at 72.79% examples, 20107 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:27,860 - INFO - EPOCH 31 - PROGRESS: at 84.29% examples, 20555 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:28,916 - INFO - EPOCH 31 - PROGRESS: at 94.66% examples, 20739 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:29,324 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:29,454 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:29,455 - INFO - EPOCH - 31 : training on 503174 raw words (225559 effective words) took 10.8s, 20897 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:30,561 - INFO - EPOCH 32 - PROGRESS: at 9.14% examples, 17670 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:31,929 - INFO - EPOCH 32 - PROGRESS: at 20.94% examples, 19253 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:33,098 - INFO - EPOCH 32 - PROGRESS: at 33.26% examples, 19389 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:34,256 - INFO - EPOCH 32 - PROGRESS: at 46.30% examples, 20417 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:35,448 - INFO - EPOCH 32 - PROGRESS: at 54.72% examples, 19853 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:36,565 - INFO - EPOCH 32 - PROGRESS: at 63.55% examples, 20281 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:37,694 - INFO - EPOCH 32 - PROGRESS: at 74.74% examples, 20484 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:38,695 - INFO - EPOCH 32 - PROGRESS: at 84.29% examples, 20494 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:39,703 - INFO - EPOCH 32 - PROGRESS: at 94.66% examples, 20773 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:40,111 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:40,115 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:40,116 - INFO - EPOCH - 32 : training on 503174 raw words (225651 effective words) took 10.7s, 21169 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:41,230 - INFO - EPOCH 33 - PROGRESS: at 9.14% examples, 17464 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:42,296 - INFO - EPOCH 33 - PROGRESS: at 16.94% examples, 17434 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:43,440 - INFO - EPOCH 33 - PROGRESS: at 25.05% examples, 15512 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:44,839 - INFO - EPOCH 33 - PROGRESS: at 33.26% examples, 14943 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:46,156 - INFO - EPOCH 33 - PROGRESS: at 41.89% examples, 14730 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:47,236 - INFO - EPOCH 33 - PROGRESS: at 47.54% examples, 14258 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:48,276 - INFO - EPOCH 33 - PROGRESS: at 54.72% examples, 14592 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:49,513 - INFO - EPOCH 33 - PROGRESS: at 59.03% examples, 14027 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:50,773 - INFO - EPOCH 33 - PROGRESS: at 62.01% examples, 13142 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:51,998 - INFO - EPOCH 33 - PROGRESS: at 65.50% examples, 12487 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:53,623 - INFO - EPOCH 33 - PROGRESS: at 72.79% examples, 12194 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:54,851 - INFO - EPOCH 33 - PROGRESS: at 76.80% examples, 11740 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:55,908 - INFO - EPOCH 33 - PROGRESS: at 80.49% examples, 11459 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:56,957 - INFO - EPOCH 33 - PROGRESS: at 84.29% examples, 11256 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:58,101 - INFO - EPOCH 33 - PROGRESS: at 87.89% examples, 10979 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:00:59,425 - INFO - EPOCH 33 - PROGRESS: at 94.66% examples, 11058 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:00,412 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:00,690 - INFO - EPOCH 33 - PROGRESS: at 100.00% examples, 10989 words/s, in_qsize 0, out_qsize 1\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:00,693 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:00,693 - INFO - EPOCH - 33 : training on 503174 raw words (226081 effective words) took 20.6s, 10988 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:02,131 - INFO - EPOCH 34 - PROGRESS: at 7.08% examples, 10156 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:03,354 - INFO - EPOCH 34 - PROGRESS: at 9.24% examples, 7186 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:04,525 - INFO - EPOCH 34 - PROGRESS: at 14.99% examples, 8630 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:05,760 - INFO - EPOCH 34 - PROGRESS: at 23.61% examples, 10223 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:06,762 - INFO - EPOCH 34 - PROGRESS: at 33.16% examples, 11649 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:07,858 - INFO - EPOCH 34 - PROGRESS: at 44.15% examples, 13064 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:09,088 - INFO - EPOCH 34 - PROGRESS: at 54.72% examples, 14198 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:10,166 - INFO - EPOCH 34 - PROGRESS: at 62.01% examples, 14805 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:11,409 - INFO - EPOCH 34 - PROGRESS: at 72.90% examples, 15398 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:12,412 - INFO - EPOCH 34 - PROGRESS: at 82.44% examples, 15800 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:13,484 - INFO - EPOCH 34 - PROGRESS: at 92.92% examples, 16359 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:13,973 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:14,222 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:14,224 - INFO - EPOCH - 34 : training on 503174 raw words (225963 effective words) took 13.5s, 16702 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:15,385 - INFO - EPOCH 35 - PROGRESS: at 9.14% examples, 16827 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:16,727 - INFO - EPOCH 35 - PROGRESS: at 20.94% examples, 19093 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:17,821 - INFO - EPOCH 35 - PROGRESS: at 33.16% examples, 19716 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:19,101 - INFO - EPOCH 35 - PROGRESS: at 46.30% examples, 20126 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:20,118 - INFO - EPOCH 35 - PROGRESS: at 54.72% examples, 20212 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:21,143 - INFO - EPOCH 35 - PROGRESS: at 60.47% examples, 19610 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:22,322 - INFO - EPOCH 35 - PROGRESS: at 70.94% examples, 19857 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:23,324 - INFO - EPOCH 35 - PROGRESS: at 80.60% examples, 19942 words/s, in_qsize 2, out_qsize 1\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:24,612 - INFO - EPOCH 35 - PROGRESS: at 92.92% examples, 20140 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:25,305 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:25,402 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:25,403 - INFO - EPOCH - 35 : training on 503174 raw words (225866 effective words) took 11.2s, 20207 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:26,695 - INFO - EPOCH 36 - PROGRESS: at 10.99% examples, 18426 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:27,880 - INFO - EPOCH 36 - PROGRESS: at 21.36% examples, 18927 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:29,143 - INFO - EPOCH 36 - PROGRESS: at 35.42% examples, 20230 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:30,469 - INFO - EPOCH 36 - PROGRESS: at 48.56% examples, 20206 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:31,755 - INFO - EPOCH 36 - PROGRESS: at 57.60% examples, 20113 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:32,822 - INFO - EPOCH 36 - PROGRESS: at 63.55% examples, 19452 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:33,915 - INFO - EPOCH 36 - PROGRESS: at 72.79% examples, 19369 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:34,937 - INFO - EPOCH 36 - PROGRESS: at 82.34% examples, 19448 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:36,025 - INFO - EPOCH 36 - PROGRESS: at 92.81% examples, 19708 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:36,448 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:36,753 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:36,754 - INFO - EPOCH - 36 : training on 503174 raw words (226020 effective words) took 11.3s, 19915 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:37,828 - INFO - EPOCH 37 - PROGRESS: at 9.14% examples, 18154 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:38,845 - INFO - EPOCH 37 - PROGRESS: at 16.74% examples, 18075 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:40,187 - INFO - EPOCH 37 - PROGRESS: at 31.01% examples, 19147 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:41,406 - INFO - EPOCH 37 - PROGRESS: at 41.89% examples, 19065 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:42,544 - INFO - EPOCH 37 - PROGRESS: at 49.79% examples, 18251 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:43,647 - INFO - EPOCH 37 - PROGRESS: at 56.26% examples, 17843 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:44,900 - INFO - EPOCH 37 - PROGRESS: at 67.25% examples, 18613 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:46,075 - INFO - EPOCH 37 - PROGRESS: at 78.75% examples, 18908 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:47,143 - INFO - EPOCH 37 - PROGRESS: at 89.32% examples, 19283 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:48,013 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:48,220 - INFO - EPOCH 37 - PROGRESS: at 100.00% examples, 19621 words/s, in_qsize 0, out_qsize 1\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:48,221 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:48,221 - INFO - EPOCH - 37 : training on 503174 raw words (224962 effective words) took 11.5s, 19619 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:49,435 - INFO - EPOCH 38 - PROGRESS: at 11.29% examples, 19816 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:50,655 - INFO - EPOCH 38 - PROGRESS: at 18.99% examples, 17575 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:51,753 - INFO - EPOCH 38 - PROGRESS: at 31.01% examples, 18677 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:52,786 - INFO - EPOCH 38 - PROGRESS: at 40.04% examples, 18613 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:53,838 - INFO - EPOCH 38 - PROGRESS: at 49.79% examples, 18906 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:55,027 - INFO - EPOCH 38 - PROGRESS: at 56.16% examples, 18088 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:56,062 - INFO - EPOCH 38 - PROGRESS: at 63.55% examples, 18379 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:57,254 - INFO - EPOCH 38 - PROGRESS: at 72.79% examples, 18224 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:58,305 - INFO - EPOCH 38 - PROGRESS: at 82.34% examples, 18376 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:01:59,553 - INFO - EPOCH 38 - PROGRESS: at 92.92% examples, 18458 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:00,269 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:00,337 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:00,337 - INFO - EPOCH - 38 : training on 503174 raw words (225728 effective words) took 12.1s, 18632 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:01,840 - INFO - EPOCH 39 - PROGRESS: at 11.29% examples, 15921 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:03,108 - INFO - EPOCH 39 - PROGRESS: at 18.69% examples, 15386 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:04,265 - INFO - EPOCH 39 - PROGRESS: at 33.16% examples, 17944 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:05,336 - INFO - EPOCH 39 - PROGRESS: at 44.15% examples, 18651 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:06,339 - INFO - EPOCH 39 - PROGRESS: at 53.08% examples, 19111 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:07,348 - INFO - EPOCH 39 - PROGRESS: at 60.47% examples, 19296 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:08,528 - INFO - EPOCH 39 - PROGRESS: at 70.94% examples, 19585 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:09,644 - INFO - EPOCH 39 - PROGRESS: at 82.34% examples, 19876 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:10,761 - INFO - EPOCH 39 - PROGRESS: at 92.81% examples, 20030 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:11,401 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:11,441 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:11,441 - INFO - EPOCH - 39 : training on 503174 raw words (225465 effective words) took 11.1s, 20307 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:12,443 - INFO - EPOCH 40 - PROGRESS: at 9.14% examples, 19359 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:13,525 - INFO - EPOCH 40 - PROGRESS: at 18.69% examples, 20488 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:14,610 - INFO - EPOCH 40 - PROGRESS: at 31.01% examples, 20759 words/s, in_qsize 4, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:15,852 - INFO - EPOCH 40 - PROGRESS: at 42.30% examples, 20252 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:17,015 - INFO - EPOCH 40 - PROGRESS: at 53.08% examples, 20617 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:18,080 - INFO - EPOCH 40 - PROGRESS: at 62.01% examples, 21084 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:19,083 - INFO - EPOCH 40 - PROGRESS: at 70.94% examples, 20966 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:20,216 - INFO - EPOCH 40 - PROGRESS: at 82.44% examples, 21088 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:21,219 - INFO - EPOCH 40 - PROGRESS: at 91.07% examples, 20963 words/s, in_qsize 3, out_qsize 0\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,176 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,190 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,191 - INFO - EPOCH - 40 : training on 503174 raw words (225722 effective words) took 10.7s, 21000 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,192 - INFO - training on a 20126960 raw words (9031014 effective words) took 507.3s, 17803 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m /envs/python38/lib/python3.8/site-packages/fse/models/base_s2v.py:114: UserWarning: C extension not loaded, training/inferring will be slow. Install a C compiler and reinstall fse.\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m   warnings.warn(\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,197 - INFO - no frequency mode: using wordfreq for estimation of frequency for language: en\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,366 - INFO - scanning all indexed sentences and their word counts\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,368 - INFO - finished scanning 974 sentences with an average length of 516 and 503174 total words\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,373 - INFO - estimated memory for 974 sentences with 300 dimensions and 12115 vocabulary: 15 MB (0 GB)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,374 - INFO - initializing sentence vectors for 974 sentences\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,377 - INFO - pre-computing SIF weights for 12115 words\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,395 - INFO - begin training\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,897 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,900 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,900 - INFO - no removal of principal components\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,900 - INFO - training on 974 effective sentences with 503174 effective words took 0s with 1928 sentences/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,911 - INFO - Training blogs model for 9 blogs of language: es using the following hyperparameters:\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m {\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"min_count\": \"0\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"size\": \"300\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"sg\": \"1\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"window\": \"15\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"iter\": \"40\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"sample\": \"6e-05\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"hs\": \"0\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"negative\": \"15\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"ns_exponent\": \"-0.5\",\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m  \"workers\": \"2\"\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m }\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,912 - INFO - collecting all words and their counts\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,912 - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,913 - INFO - collected 1134 word types from a corpus of 3761 raw words and 9 sentences\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,913 - INFO - Loading a fresh vocabulary\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,924 - INFO - effective_min_count=0 retains 1134 unique words (100% of original 1134, drops 0)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,924 - INFO - effective_min_count=0 leaves 3761 word corpus (100% of original 3761, drops 0)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,931 - INFO - deleting the raw counts dictionary of 1134 items\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,931 - INFO - sample=6e-05 downsamples 1134 most-common words\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,931 - INFO - downsampling leaves estimated 1087 word corpus (28.9% of prior 3761)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,933 - INFO - estimated required memory for 1134 words and 300 dimensions: 3288600 bytes\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:22,934 - INFO - resetting layer weights\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,277 - INFO - training model with 2 workers on 1134 vocabulary and 300 features, using sg=1 hs=0 sample=6e-05 negative=15 window=15\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,285 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,364 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,364 - INFO - EPOCH - 1 : training on 3761 raw words (1066 effective words) took 0.1s, 12434 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,366 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,437 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,437 - INFO - EPOCH - 2 : training on 3761 raw words (1081 effective words) took 0.1s, 15065 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,440 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,521 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,521 - INFO - EPOCH - 3 : training on 3761 raw words (1053 effective words) took 0.1s, 12767 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,524 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,609 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,610 - INFO - EPOCH - 4 : training on 3761 raw words (1072 effective words) took 0.1s, 12194 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,619 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,696 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,696 - INFO - EPOCH - 5 : training on 3761 raw words (1121 effective words) took 0.1s, 13152 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,705 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,777 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,778 - INFO - EPOCH - 6 : training on 3761 raw words (1123 effective words) took 0.1s, 14027 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,785 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,866 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,866 - INFO - EPOCH - 7 : training on 3761 raw words (1122 effective words) took 0.1s, 12905 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,869 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,943 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,943 - INFO - EPOCH - 8 : training on 3761 raw words (1102 effective words) took 0.1s, 14437 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:23,949 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,032 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,032 - INFO - EPOCH - 9 : training on 3761 raw words (1102 effective words) took 0.1s, 12526 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,034 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,150 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,151 - INFO - EPOCH - 10 : training on 3761 raw words (1098 effective words) took 0.1s, 9325 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,153 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,249 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,249 - INFO - EPOCH - 11 : training on 3761 raw words (1044 effective words) took 0.1s, 10715 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,253 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,319 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,320 - INFO - EPOCH - 12 : training on 3761 raw words (1046 effective words) took 0.1s, 15148 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,321 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,394 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,394 - INFO - EPOCH - 13 : training on 3761 raw words (1078 effective words) took 0.1s, 14634 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,396 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,484 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,484 - INFO - EPOCH - 14 : training on 3761 raw words (1091 effective words) took 0.1s, 12403 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,486 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,604 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,604 - INFO - EPOCH - 15 : training on 3761 raw words (1123 effective words) took 0.1s, 9464 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,609 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,752 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,753 - INFO - EPOCH - 16 : training on 3761 raw words (1099 effective words) took 0.1s, 7588 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,757 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,843 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,843 - INFO - EPOCH - 17 : training on 3761 raw words (1093 effective words) took 0.1s, 12233 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,846 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,924 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,925 - INFO - EPOCH - 18 : training on 3761 raw words (1069 effective words) took 0.1s, 13411 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:24,929 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,019 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,020 - INFO - EPOCH - 19 : training on 3761 raw words (1125 effective words) took 0.1s, 11972 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,022 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,103 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,103 - INFO - EPOCH - 20 : training on 3761 raw words (1084 effective words) took 0.1s, 13269 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,106 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,190 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,190 - INFO - EPOCH - 21 : training on 3761 raw words (1081 effective words) took 0.1s, 12877 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,192 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,283 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,283 - INFO - EPOCH - 22 : training on 3761 raw words (1102 effective words) took 0.1s, 12057 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,289 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,369 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,370 - INFO - EPOCH - 23 : training on 3761 raw words (1107 effective words) took 0.1s, 12959 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,371 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,496 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,496 - INFO - EPOCH - 24 : training on 3761 raw words (1077 effective words) took 0.1s, 8648 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,501 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,600 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,600 - INFO - EPOCH - 25 : training on 3761 raw words (1081 effective words) took 0.1s, 10797 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,602 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,681 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,681 - INFO - EPOCH - 26 : training on 3761 raw words (1062 effective words) took 0.1s, 13295 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,689 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,769 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,770 - INFO - EPOCH - 27 : training on 3761 raw words (1074 effective words) took 0.1s, 12267 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,772 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,862 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,863 - INFO - EPOCH - 28 : training on 3761 raw words (1067 effective words) took 0.1s, 11597 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,865 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,957 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,958 - INFO - EPOCH - 29 : training on 3761 raw words (1079 effective words) took 0.1s, 11559 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:25,960 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,047 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,048 - INFO - EPOCH - 30 : training on 3761 raw words (1085 effective words) took 0.1s, 12209 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,050 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,130 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,131 - INFO - EPOCH - 31 : training on 3761 raw words (1105 effective words) took 0.1s, 13547 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,137 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,216 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,216 - INFO - EPOCH - 32 : training on 3761 raw words (1085 effective words) took 0.1s, 12871 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,218 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,308 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,309 - INFO - EPOCH - 33 : training on 3761 raw words (1085 effective words) took 0.1s, 11848 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,310 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,402 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,403 - INFO - EPOCH - 34 : training on 3761 raw words (1097 effective words) took 0.1s, 11728 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,405 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,489 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,489 - INFO - EPOCH - 35 : training on 3761 raw words (1092 effective words) took 0.1s, 12830 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,493 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,565 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,565 - INFO - EPOCH - 36 : training on 3761 raw words (1079 effective words) took 0.1s, 14422 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,567 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,636 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,636 - INFO - EPOCH - 37 : training on 3761 raw words (1118 effective words) took 0.1s, 15840 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,641 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,735 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,735 - INFO - EPOCH - 38 : training on 3761 raw words (1098 effective words) took 0.1s, 11200 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,741 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,844 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,844 - INFO - EPOCH - 39 : training on 3761 raw words (1042 effective words) took 0.1s, 9701 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,846 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,950 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,950 - INFO - EPOCH - 40 : training on 3761 raw words (1068 effective words) took 0.1s, 10148 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,950 - INFO - training on a 150440 raw words (43476 effective words) took 3.7s, 11837 effective words/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:26,952 - INFO - no frequency mode: using wordfreq for estimation of frequency for language: es\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:27,185 - INFO - scanning all indexed sentences and their word counts\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:27,185 - INFO - finished scanning 9 sentences with an average length of 417 and 3761 total words\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:27,186 - INFO - estimated memory for 9 sentences with 300 dimensions and 1134 vocabulary: 1 MB (0 GB)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:27,186 - INFO - initializing sentence vectors for 9 sentences\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:27,186 - INFO - pre-computing SIF weights for 1134 words\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:27,187 - INFO - begin training\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:27,189 - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:27,195 - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:27,196 - INFO - no removal of principal components\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:27,196 - INFO - training on 9 effective sentences with 3761 effective words took 0s with 1008 sentences/s\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:02:27,196 - INFO - getting cache results prediction...\n",
      "Extracting 100 predictions:  78% 757/974 [08:04<02:34,  1.40it/s]2023-02-07 04:10:31,733 - WARNING - found 1 empty sentences\n",
      "Extracting 100 predictions: 100% 974/974 [12:05<00:00,  1.34it/s]\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:14:32,933 - INFO - getting cache results prediction...\n",
      "Extracting 9 predictions: 100% 9/9 [00:00<00:00, 64.58it/s]\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:14:33,077 - INFO - Training tfidf for model analysis and visualizing\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:14:33,360 - INFO - getting model summary tables\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:14:33,536 - INFO - prepare embeddings configuration for visualization charts\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:14:41,964 - INFO - generate accuracy chart\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:14:42,052 - INFO - generate blogs embedding chart\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:14:42,711 - INFO - getting model summary tables\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:14:42,751 - INFO - prepare embeddings configuration for visualization charts\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:14:43,014 - INFO - generate accuracy chart\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:14:43,022 - INFO - generate blogs embedding chart\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:14:43,814 - INFO - Saving model to /opt/ml/model/bv_model_en_wp_koombea20stg.bv\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:14:43,815 - INFO - saving SIF object under /opt/ml/model/bv_model_en_wp_koombea20stg.bv, separately None\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:14:44,118 - INFO - saved /opt/ml/model/bv_model_en_wp_koombea20stg.bv\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:14:44,333 - INFO - Saving model to /opt/ml/model/bv_model_es_wp_koombea20stg.bv\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:14:44,333 - INFO - saving SIF object under /opt/ml/model/bv_model_es_wp_koombea20stg.bv, separately None\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:14:44,354 - INFO - saved /opt/ml/model/bv_model_es_wp_koombea20stg.bv\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 34\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                d)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /opt/ml/code/wandb/run-20230207_035350-analysis-training-job-wp_koombea20stg/logs/debug.log\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /opt/ml/code/wandb/run-20230207_035350-analysis-training-job-wp_koombea20stg/logs/debug-internal.log\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m:          _timestamp 1675743283\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m:               _step 871\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m:            _runtime 419695\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m:     _runtime ▁█\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m:   _timestamp ▁█\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m:        _step ▁█\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m: Synced 3 W&B file(s), 8 media file(s), 8 artifact file(s) and 0 other file(s)\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m \u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msemantic-model-analisys-training-job-wp_koombea20stg\u001b[0m: \u001b[34mhttps://wandb.ai/koombea-marketing/koombea-website-ml/runs/analysis-training-job-wp_koombea20stg\u001b[0m\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe |\u001b[0m 2023-02-07 04:14:57,114 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36mpj35idw5j0-algo-1-gq5pe exited with code 0\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:creating /tmp/tmp9ydedhh_/artifacts/output/data\n",
      "INFO:root:copying /tmp/tmp9ydedhh_/algo-1-gq5pe/output/success -> /tmp/tmp9ydedhh_/artifacts/output\n",
      "INFO:root:copying /tmp/tmp9ydedhh_/model/bv_model_en_wp_koombea20stg.bv -> /tmp/tmp9ydedhh_/artifacts/model\n",
      "INFO:root:copying /tmp/tmp9ydedhh_/model/bv_model_es_wp_koombea20stg.bv -> /tmp/tmp9ydedhh_/artifacts/model\n",
      "INFO:root:copying /tmp/tmp9ydedhh_/model/idx2ids_mapping_en_wp_koombea20stg.json -> /tmp/tmp9ydedhh_/artifacts/model\n",
      "INFO:root:copying /tmp/tmp9ydedhh_/model/idx2ids_mapping_es_wp_koombea20stg.json -> /tmp/tmp9ydedhh_/artifacts/model\n",
      "INFO:root:copying /tmp/tmp9ydedhh_/model/blogs_df_wp_koombea20stg.csv -> /tmp/tmp9ydedhh_/artifacts/model\n",
      "INFO:root:copying /tmp/tmp9ydedhh_/compressed_artifacts/model.tar.gz -> /home/ec2-user/SageMaker/search/koombea_blogs_train/models\n",
      "INFO:root:copying /tmp/tmp9ydedhh_/compressed_artifacts/output.tar.gz -> /home/ec2-user/SageMaker/search/koombea_blogs_train/models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\"training\": \"file://{}/{}\".format(root_dir, \"data\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69732de8-f4da-449c-a945-7dd948576f00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38 my_env",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
